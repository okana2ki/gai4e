{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPNz8Nff6fA1gxmoqXipwqc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okana2ki/gai4e/blob/main/emotion_sns2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 棒グラフと投稿一覧表示の英語部分を日本語に変更（Geminiに指示）"
      ],
      "metadata": {
        "id": "IgIALtiUgxZJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "B7Vps1lhDjx",
        "outputId": "9bf89822-da5e-4ead-b609-3fb9bd50e881"
      },
      "source": [
        "!pip install -q -U google-genai gradio plotly pandas wordcloud matplotlib\n",
        "!apt install -y fonts-noto-cjk\n",
        "\n",
        "import google.genai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "import json, re, threading, time, queue\n",
        "\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc\"\n",
        "\n",
        "# --- データとキュー ---\n",
        "df = pd.DataFrame(columns=[\"投稿\",\"sentiment\",\"ai_comment\"])\n",
        "post_queue = queue.Queue()\n",
        "latest_ai_comment = \"\"\n",
        "\n",
        "# --- 可視化関数 ---\n",
        "def update_visualizations():\n",
        "    global df\n",
        "    # 感情ラベルの日本語マッピング\n",
        "    sentiment_labels_jp = {\n",
        "        \"interest\": \"興味\",\n",
        "        \"understanding\": \"理解\",\n",
        "        \"confusion\": \"困惑\",\n",
        "        \"neutral\": \"中立\",\n",
        "        \"pending\": \"処理中\"\n",
        "    }\n",
        "    df_display = df.copy()\n",
        "    df_display['sentiment'] = df_display['sentiment'].map(sentiment_labels_jp)\n",
        "\n",
        "    fig = px.histogram(\n",
        "        df_display,\n",
        "        x=\"sentiment\",\n",
        "        color=\"sentiment\",\n",
        "        text_auto=True,\n",
        "        category_orders={\"sentiment\":[\"興味\",\"理解\",\"困惑\",\"中立\",\"処理中\"]},\n",
        "        title=\"オープンキャンパス感想のリアルタイム感情分析\",\n",
        "        color_discrete_map={\"興味\":\"gold\",\"理解\":\"lightblue\",\"困惑\":\"orange\",\"中立\":\"lightgrey\",\"処理中\":\"lightpink\"}\n",
        "    )\n",
        "    fig.update_layout(yaxis_title=\"投稿数\", xaxis_title=\"感情\")\n",
        "    all_text = \" \".join(df[\"投稿\"].tolist())\n",
        "    wc = WordCloud(width=400, height=300, background_color=\"white\", font_path=FONT_PATH).generate(all_text)\n",
        "    wc_image = wc.to_image()\n",
        "    return fig, wc_image, df_display\n",
        "\n",
        "# --- バックグラウンドLLM処理 ---\n",
        "def process_queue():\n",
        "    global df, latest_ai_comment\n",
        "    while True:\n",
        "        try:\n",
        "            text, row_index = post_queue.get(timeout=1)\n",
        "        except queue.Empty:\n",
        "            time.sleep(1)\n",
        "            continue\n",
        "        system_instruction = (\n",
        "            \"あなたはSNS分析の専門家です。\"\n",
        "            \"以下の文章を解析して、JSON形式で出力してください。\"\n",
        "            \"JSONには2つのキーを含めます：\"\n",
        "            \" 1) 'sentiment' : interest, understanding, confusion, neutral のいずれか\"\n",
        "            \" 2) 'ai_comment' : オープンキャンパスに来場した高校生を元気づけ、この大学（宮崎産業経営大学）に入学したくなるようなポジティブコメント\"\n",
        "            \"出力は必ずJSON形式のみで返してください。\"\n",
        "        )\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-lite\",\n",
        "            config=genai.types.GenerateContentConfig(system_instruction=system_instruction),\n",
        "            contents=text\n",
        "        )\n",
        "        match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                result = json.loads(match.group())\n",
        "                sentiment = result.get(\"sentiment\",\"neutral\").strip().lower()\n",
        "                ai_comment = result.get(\"ai_comment\",\"\")\n",
        "            except:\n",
        "                sentiment = \"neutral\"\n",
        "                ai_comment = response.text\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "            ai_comment = response.text\n",
        "        if sentiment not in [\"interest\",\"understanding\",\"confusion\",\"neutral\"]:\n",
        "            sentiment = \"neutral\"\n",
        "        df.loc[row_index,\"sentiment\"] = sentiment\n",
        "        df.loc[row_index,\"ai_comment\"] = ai_comment\n",
        "        latest_ai_comment = ai_comment\n",
        "        post_queue.task_done()\n",
        "        time.sleep(4)  # 15RPM制限対応\n",
        "\n",
        "threading.Thread(target=process_queue, daemon=True).start()\n",
        "\n",
        "# --- 投稿処理 ---\n",
        "def submit_post(text):\n",
        "    global df, post_queue\n",
        "    row_index = len(df)\n",
        "    df.loc[row_index] = [text, \"pending\",\"\"]\n",
        "    post_queue.put((text,row_index))\n",
        "    fig, wc_image, df_display = update_visualizations()\n",
        "    return fig, wc_image, \"\", \"投稿完了。LLM解析は順番に処理されます。\", df_display\n",
        "\n",
        "# --- 更新ボタン処理 ---\n",
        "def update_display(input_text_value):\n",
        "    fig, wc_image, df_display = update_visualizations()\n",
        "    matching_rows = df[df[\"投稿\"] == input_text_value]\n",
        "    if not matching_rows.empty:\n",
        "        ai_comment = matching_rows.iloc[-1][\"ai_comment\"]\n",
        "    else:\n",
        "        ai_comment = \"\"\n",
        "    return fig, wc_image, ai_comment, df_display\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# オープンキャンパス感想SNSデモ\")\n",
        "    input_text = gr.Textbox(label=\"感想入力\")\n",
        "    submit_btn = gr.Button(\"投稿\")\n",
        "    update_btn = gr.Button(\"集計更新\")\n",
        "    ai_comment_output = gr.Textbox(label=\"AIコメント\", interactive=False)\n",
        "    status_output = gr.Textbox(label=\"投稿ステータス\", interactive=False)\n",
        "    graph_output = gr.Plot(label=\"感情分析グラフ\")\n",
        "    wc_output = gr.Image(label=\"ワードクラウド\")\n",
        "    dataframe_output = gr.DataFrame(label=\"投稿一覧\")\n",
        "\n",
        "    submit_btn.click(submit_post, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output, status_output, dataframe_output])\n",
        "    update_btn.click(update_display, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output, dataframe_output])\n",
        "\n",
        "demo.launch()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto-cjk is already the newest version (1:20220127+repack1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e983fa13f4c2b211c1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e983fa13f4c2b211c1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 投稿された感想を表示する機能を追加する（Geminiに指示）"
      ],
      "metadata": {
        "id": "QcKKlgL6NBAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai gradio plotly pandas wordcloud matplotlib\n",
        "!apt install -y fonts-noto-cjk\n",
        "\n",
        "import google.genai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "import json, re, threading, time, queue\n",
        "\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc\"\n",
        "\n",
        "# --- データとキュー ---\n",
        "df = pd.DataFrame(columns=[\"投稿\",\"sentiment\",\"ai_comment\"])\n",
        "post_queue = queue.Queue()\n",
        "latest_ai_comment = \"\"\n",
        "\n",
        "# --- 可視化関数 ---\n",
        "def update_visualizations():\n",
        "    global df\n",
        "    fig = px.histogram(\n",
        "        df,\n",
        "        x=\"sentiment\",\n",
        "        color=\"sentiment\",\n",
        "        text_auto=True,\n",
        "        category_orders={\"sentiment\":[\"interest\",\"understanding\",\"confusion\",\"neutral\",\"pending\"]},\n",
        "        title=\"オープンキャンパス感想のリアルタイム感情分析\",\n",
        "        color_discrete_map={\"interest\":\"gold\",\"understanding\":\"lightblue\",\"confusion\":\"orange\",\"neutral\":\"lightgrey\",\"pending\":\"lightpink\"}\n",
        "    )\n",
        "    fig.update_layout(yaxis_title=\"投稿数\", xaxis_title=\"感情\")\n",
        "    all_text = \" \".join(df[\"投稿\"].tolist())\n",
        "    wc = WordCloud(width=400, height=300, background_color=\"white\", font_path=FONT_PATH).generate(all_text)\n",
        "    wc_image = wc.to_image()\n",
        "    return fig, wc_image\n",
        "\n",
        "# --- バックグラウンドLLM処理 ---\n",
        "def process_queue():\n",
        "    global df, latest_ai_comment\n",
        "    while True:\n",
        "        try:\n",
        "            text, row_index = post_queue.get(timeout=1)\n",
        "        except queue.Empty:\n",
        "            time.sleep(1)\n",
        "            continue\n",
        "        system_instruction = (\n",
        "            \"あなたはSNS分析の専門家です。\"\n",
        "            \"以下の文章を解析して、JSON形式で出力してください。\"\n",
        "            \"JSONには2つのキーを含めます：\"\n",
        "            \" 1) 'sentiment' : interest, understanding, confusion, neutral のいずれか\"\n",
        "            \" 2) 'ai_comment' : オープンキャンパスに来場した高校生を元気づけ、この大学（宮崎産業経営大学）に入学したくなるようなポジティブコメント\"\n",
        "            \"出力は必ずJSON形式のみで返してください。\"\n",
        "        )\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-lite\",\n",
        "            config=genai.types.GenerateContentConfig(system_instruction=system_instruction),\n",
        "            contents=text\n",
        "        )\n",
        "        match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                result = json.loads(match.group())\n",
        "                sentiment = result.get(\"sentiment\",\"neutral\").strip().lower()\n",
        "                ai_comment = result.get(\"ai_comment\",\"\")\n",
        "            except:\n",
        "                sentiment = \"neutral\"\n",
        "                ai_comment = response.text\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "            ai_comment = response.text\n",
        "        if sentiment not in [\"interest\",\"understanding\",\"confusion\",\"neutral\"]:\n",
        "            sentiment = \"neutral\"\n",
        "        df.loc[row_index,\"sentiment\"] = sentiment\n",
        "        df.loc[row_index,\"ai_comment\"] = ai_comment\n",
        "        latest_ai_comment = ai_comment\n",
        "        post_queue.task_done()\n",
        "        time.sleep(4)  # 15RPM制限対応\n",
        "\n",
        "threading.Thread(target=process_queue, daemon=True).start()\n",
        "\n",
        "# --- 投稿処理 ---\n",
        "def submit_post(text):\n",
        "    global df, post_queue\n",
        "    row_index = len(df)\n",
        "    df.loc[row_index] = [text, \"pending\",\"\"]\n",
        "    post_queue.put((text,row_index))\n",
        "    fig, wc_image = update_visualizations()\n",
        "    return fig, wc_image, \"\", \"投稿完了。LLM解析は順番に処理されます。\", df\n",
        "\n",
        "# --- 更新ボタン処理 ---\n",
        "def update_display(input_text_value):\n",
        "    fig, wc_image = update_visualizations()\n",
        "    matching_rows = df[df[\"投稿\"] == input_text_value]\n",
        "    if not matching_rows.empty:\n",
        "        ai_comment = matching_rows.iloc[-1][\"ai_comment\"]\n",
        "    else:\n",
        "        ai_comment = \"\"\n",
        "    return fig, wc_image, ai_comment, df\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# オープンキャンパス感想SNSデモ\")\n",
        "    input_text = gr.Textbox(label=\"感想入力\")\n",
        "    submit_btn = gr.Button(\"投稿\")\n",
        "    update_btn = gr.Button(\"集計更新\")\n",
        "    ai_comment_output = gr.Textbox(label=\"AIコメント\", interactive=False)\n",
        "    status_output = gr.Textbox(label=\"投稿ステータス\", interactive=False)\n",
        "    graph_output = gr.Plot(label=\"感情分析グラフ\")\n",
        "    wc_output = gr.Image(label=\"ワードクラウド\")\n",
        "    dataframe_output = gr.DataFrame(label=\"投稿一覧\")\n",
        "\n",
        "    submit_btn.click(submit_post, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output, status_output, dataframe_output])\n",
        "    update_btn.click(update_display, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output, dataframe_output])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "0DPg1Gb_NsD8",
        "outputId": "aad5134d-cc10-4e81-bb84-e92d9a35d01c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto-cjk is already the newest version (1:20220127+repack1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c2f7d8ca41496d198d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c2f7d8ca41496d198d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# システム指示の修正（Geminiに指示）\n",
        "\n",
        "システム指示を以下のように変えて下さい。分析する感情の種類を変えたので、スクリプトの他の対応する部分もそれに応じて変えて下さい。必要最小限の修正にとどめて、他の部分はそのままにして下さい。\n",
        "```\n",
        "        system_instruction = (\n",
        "            \"あなたはSNS分析の専門家です。\"\n",
        "            \"以下の文章を解析して、JSON形式で出力してください。\"\n",
        "            \"JSONには2つのキーを含めます：\"\n",
        "            \" 1) 'sentiment' : interest, understanding, confusion, neutral のいずれか\"\n",
        "            \" 2) 'ai_comment' : オープンキャンパスに来場した高校生を元気づけ、この大学（宮崎産業経営大学）に入学したくなるようなポジティブコメント\"\n",
        "            \"出力は必ずJSON形式のみで返してください。\"\n",
        "        )\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-d3iSb4NLJjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai gradio plotly pandas wordcloud matplotlib\n",
        "!apt install -y fonts-noto-cjk\n",
        "\n",
        "import google.genai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "import json, re, threading, time, queue\n",
        "\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc\"\n",
        "\n",
        "# --- データとキュー ---\n",
        "df = pd.DataFrame(columns=[\"投稿\",\"sentiment\",\"ai_comment\"])\n",
        "post_queue = queue.Queue()\n",
        "latest_ai_comment = \"\"\n",
        "\n",
        "# --- 可視化関数 ---\n",
        "def update_visualizations():\n",
        "    global df\n",
        "    fig = px.histogram(\n",
        "        df,\n",
        "        x=\"sentiment\",\n",
        "        color=\"sentiment\",\n",
        "        text_auto=True,\n",
        "        category_orders={\"sentiment\":[\"interest\",\"understanding\",\"confusion\",\"neutral\",\"pending\"]},\n",
        "        title=\"オープンキャンパス感想のリアルタイム感情分析\",\n",
        "        color_discrete_map={\"interest\":\"gold\",\"understanding\":\"lightblue\",\"confusion\":\"orange\",\"neutral\":\"lightgrey\",\"pending\":\"lightpink\"}\n",
        "    )\n",
        "    fig.update_layout(yaxis_title=\"投稿数\", xaxis_title=\"感情\")\n",
        "    all_text = \" \".join(df[\"投稿\"].tolist())\n",
        "    wc = WordCloud(width=400, height=300, background_color=\"white\", font_path=FONT_PATH).generate(all_text)\n",
        "    wc_image = wc.to_image()\n",
        "    return fig, wc_image\n",
        "\n",
        "# --- バックグラウンドLLM処理 ---\n",
        "def process_queue():\n",
        "    global df, latest_ai_comment\n",
        "    while True:\n",
        "        try:\n",
        "            text, row_index = post_queue.get(timeout=1)\n",
        "        except queue.Empty:\n",
        "            time.sleep(1)\n",
        "            continue\n",
        "        system_instruction = (\n",
        "            \"あなたはSNS分析の専門家です。\"\n",
        "            \"以下の文章を解析して、JSON形式で出力してください。\"\n",
        "            \"JSONには2つのキーを含めます：\"\n",
        "            \" 1) 'sentiment' : interest, understanding, confusion, neutral のいずれか\"\n",
        "            \" 2) 'ai_comment' : オープンキャンパスに来場した高校生を元気づけ、この大学（宮崎産業経営大学）に入学したくなるようなポジティブコメント\"\n",
        "            \"出力は必ずJSON形式のみで返してください。\"\n",
        "        )\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-lite\",\n",
        "            config=genai.types.GenerateContentConfig(system_instruction=system_instruction),\n",
        "            contents=text\n",
        "        )\n",
        "        match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                result = json.loads(match.group())\n",
        "                sentiment = result.get(\"sentiment\",\"neutral\").strip().lower()\n",
        "                ai_comment = result.get(\"ai_comment\",\"\")\n",
        "            except:\n",
        "                sentiment = \"neutral\"\n",
        "                ai_comment = response.text\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "            ai_comment = response.text\n",
        "        if sentiment not in [\"interest\",\"understanding\",\"confusion\",\"neutral\"]:\n",
        "            sentiment = \"neutral\"\n",
        "        df.loc[row_index,\"sentiment\"] = sentiment\n",
        "        df.loc[row_index,\"ai_comment\"] = ai_comment\n",
        "        latest_ai_comment = ai_comment\n",
        "        post_queue.task_done()\n",
        "        time.sleep(4)  # 15RPM制限対応\n",
        "\n",
        "threading.Thread(target=process_queue, daemon=True).start()\n",
        "\n",
        "# --- 投稿処理 ---\n",
        "def submit_post(text):\n",
        "    global df, post_queue\n",
        "    row_index = len(df)\n",
        "    df.loc[row_index] = [text, \"pending\",\"\"]\n",
        "    post_queue.put((text,row_index))\n",
        "    fig, wc_image = update_visualizations()\n",
        "    return fig, wc_image, \"\", \"投稿完了。LLM解析は順番に処理されます。\"\n",
        "\n",
        "# --- 更新ボタン処理 ---\n",
        "def update_display(input_text_value):\n",
        "    fig, wc_image = update_visualizations()\n",
        "    matching_rows = df[df[\"投稿\"] == input_text_value]\n",
        "    if not matching_rows.empty:\n",
        "        ai_comment = matching_rows.iloc[-1][\"ai_comment\"]\n",
        "    else:\n",
        "        ai_comment = \"\"\n",
        "    return fig, wc_image, ai_comment\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# オープンキャンパス感想SNSデモ\")\n",
        "    input_text = gr.Textbox(label=\"感想入力\")\n",
        "    submit_btn = gr.Button(\"投稿\")\n",
        "    update_btn = gr.Button(\"集計更新\")\n",
        "    ai_comment_output = gr.Textbox(label=\"AIコメント\", interactive=False)\n",
        "    status_output = gr.Textbox(label=\"投稿ステータス\", interactive=False)\n",
        "    graph_output = gr.Plot(label=\"感情分析グラフ\")\n",
        "    wc_output = gr.Image(label=\"ワードクラウド\")\n",
        "\n",
        "    submit_btn.click(submit_post, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output, status_output])\n",
        "    update_btn.click(update_display, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "gH-dQttkMQ0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 以下は古いバージョン（GPT-5に依頼して作成）"
      ],
      "metadata": {
        "id": "fSZ-rQs0XWLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai gradio plotly pandas wordcloud matplotlib\n",
        "!apt install -y fonts-noto-cjk\n",
        "\n",
        "import google.genai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "import json, re, threading, time, queue\n",
        "\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc\"\n",
        "\n",
        "# 投稿保存\n",
        "df = pd.DataFrame(columns=[\"投稿\",\"sentiment\",\"ai_comment\"])\n",
        "# LLM用キュー\n",
        "post_queue = queue.Queue()\n",
        "# 最新AIコメント保持（バックグラウンド用）\n",
        "latest_ai_comment = \"\"\n",
        "\n",
        "# --- 集計更新 ---\n",
        "def update_visualizations():\n",
        "    global df\n",
        "    # 棒グラフ\n",
        "    fig = px.histogram(\n",
        "        df,\n",
        "        x=\"sentiment\",\n",
        "        color=\"sentiment\",\n",
        "        text_auto=True,\n",
        "        category_orders={\"sentiment\":[\"joy\",\"surprise\",\"confusion\",\"neutral\",\"pending\"]},\n",
        "        title=\"オープンキャンパス感想のリアルタイム感情分析\",\n",
        "        color_discrete_map={\"joy\":\"gold\",\"surprise\":\"lightblue\",\"confusion\":\"orange\",\"neutral\":\"lightgrey\",\"pending\":\"lightpink\"}\n",
        "    )\n",
        "    fig.update_layout(yaxis_title=\"投稿数\", xaxis_title=\"感情\")\n",
        "    # ワードクラウド\n",
        "    all_text = \" \".join(df[\"投稿\"].tolist())\n",
        "    wc = WordCloud(width=400, height=300, background_color=\"white\", font_path=FONT_PATH).generate(all_text)\n",
        "    wc_image = wc.to_image()\n",
        "    return fig, wc_image\n",
        "\n",
        "# --- バックグラウンドLLM処理 ---\n",
        "def process_queue():\n",
        "    global df, latest_ai_comment\n",
        "    while True:\n",
        "        try:\n",
        "            text, row_index = post_queue.get(timeout=1)\n",
        "        except queue.Empty:\n",
        "            time.sleep(1)\n",
        "            continue\n",
        "        # Gemini呼び出し\n",
        "        system_instruction = (\n",
        "            \"あなたはSNS分析の専門家です。\"\n",
        "            \"以下の文章を解析して、JSON形式で出力してください。\"\n",
        "            \"JSONには2つのキーを含めます：\"\n",
        "            \" 1) 'sentiment' : joy, surprise, confusion, neutral のいずれか\"\n",
        "            \" 2) 'ai_comment' : 短いポジティブコメント\"\n",
        "            \"出力は必ずJSON形式のみで返してください。\"\n",
        "        )\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-lite\",\n",
        "            config=genai.types.GenerateContentConfig(system_instruction=system_instruction),\n",
        "            contents=text\n",
        "        )\n",
        "        # JSON抽出\n",
        "        match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                result = json.loads(match.group())\n",
        "                sentiment = result.get(\"sentiment\",\"neutral\").strip().lower()\n",
        "                ai_comment = result.get(\"ai_comment\",\"\")\n",
        "            except:\n",
        "                sentiment = \"neutral\"\n",
        "                ai_comment = response.text\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "            ai_comment = response.text\n",
        "        if sentiment not in [\"joy\",\"surprise\",\"confusion\",\"neutral\"]:\n",
        "            sentiment = \"neutral\"\n",
        "        # DataFrame更新\n",
        "        df.loc[row_index,\"sentiment\"] = sentiment\n",
        "        df.loc[row_index,\"ai_comment\"] = ai_comment\n",
        "        latest_ai_comment = ai_comment\n",
        "        post_queue.task_done()\n",
        "        time.sleep(4)  # 15RPM制限に合わせて4秒に1回\n",
        "\n",
        "# バックグラウンドスレッド開始\n",
        "threading.Thread(target=process_queue, daemon=True).start()\n",
        "\n",
        "# --- 投稿処理 ---\n",
        "def submit_post(text):\n",
        "    global df, post_queue\n",
        "    row_index = len(df)\n",
        "    df.loc[row_index] = [text, \"pending\",\"\"]\n",
        "    post_queue.put((text,row_index))\n",
        "    fig, wc_image = update_visualizations()\n",
        "    # ステータス用欄に表示\n",
        "    return fig, wc_image, \"\", \"投稿完了。LLM解析は順番に処理されます。\"\n",
        "\n",
        "# --- 更新ボタン処理（修正版） ---\n",
        "def update_display(input_text_value):\n",
        "    fig, wc_image = update_visualizations()\n",
        "\n",
        "    # 感想入力欄に書かれている内容に対応するAIコメントを取得\n",
        "    matching_rows = df[df[\"投稿\"] == input_text_value]\n",
        "    if not matching_rows.empty:\n",
        "        # 最新の行を取得\n",
        "        ai_comment = matching_rows.iloc[-1][\"ai_comment\"]\n",
        "    else:\n",
        "        ai_comment = \"\"  # 投稿されていない場合は空欄\n",
        "\n",
        "    return fig, wc_image, ai_comment\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# オープンキャンパス感想SNSデモ\")\n",
        "    input_text = gr.Textbox(label=\"感想入力\")\n",
        "    submit_btn = gr.Button(\"投稿\")\n",
        "    update_btn = gr.Button(\"集計更新\")\n",
        "    ai_comment_output = gr.Textbox(label=\"AIコメント\", interactive=False)\n",
        "    status_output = gr.Textbox(label=\"投稿ステータス\", interactive=False)\n",
        "    graph_output = gr.Plot(label=\"感情分析グラフ\")\n",
        "    wc_output = gr.Image(label=\"ワードクラウド\")\n",
        "\n",
        "    # 投稿ボタン：集計グラフとワードクラウド更新 + 投稿ステータス表示\n",
        "    submit_btn.click(submit_post, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output, status_output])\n",
        "    # 更新ボタン：集計グラフ・ワードクラウド・入力欄に対応する最新AIコメント表示\n",
        "    update_btn.click(update_display, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "dqwHdffdK0pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai gradio plotly pandas wordcloud matplotlib\n",
        "!apt install -y fonts-noto-cjk\n",
        "import google.genai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "import json, re, threading, time, queue\n",
        "\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc\"\n",
        "\n",
        "# 投稿保存\n",
        "df = pd.DataFrame(columns=[\"投稿\",\"sentiment\",\"ai_comment\"])\n",
        "# LLM用キュー\n",
        "post_queue = queue.Queue()\n",
        "# 最新AIコメント保持\n",
        "latest_ai_comment = \"\"\n",
        "\n",
        "# --- 集計更新 ---\n",
        "def update_visualizations():\n",
        "    global df\n",
        "    # 棒グラフ\n",
        "    fig = px.histogram(\n",
        "        df,\n",
        "        x=\"sentiment\",\n",
        "        color=\"sentiment\",\n",
        "        text_auto=True,\n",
        "        category_orders={\"sentiment\":[\"joy\",\"surprise\",\"confusion\",\"neutral\",\"pending\"]},\n",
        "        title=\"オープンキャンパス感想のリアルタイム感情分析\",\n",
        "        color_discrete_map={\"joy\":\"gold\",\"surprise\":\"lightblue\",\"confusion\":\"orange\",\"neutral\":\"lightgrey\",\"pending\":\"lightpink\"}\n",
        "    )\n",
        "    fig.update_layout(yaxis_title=\"投稿数\", xaxis_title=\"感情\")\n",
        "    # ワードクラウド\n",
        "    all_text = \" \".join(df[\"投稿\"].tolist())\n",
        "    wc = WordCloud(width=400, height=300, background_color=\"white\", font_path=FONT_PATH).generate(all_text)\n",
        "    wc_image = wc.to_image()\n",
        "    return fig, wc_image\n",
        "\n",
        "# --- バックグラウンドLLM処理 ---\n",
        "def process_queue():\n",
        "    global df, latest_ai_comment\n",
        "    while True:\n",
        "        try:\n",
        "            text, row_index = post_queue.get(timeout=1)\n",
        "        except queue.Empty:\n",
        "            time.sleep(1)\n",
        "            continue\n",
        "        # Gemini呼び出し\n",
        "        system_instruction = (\n",
        "            \"あなたはSNS分析の専門家です。\"\n",
        "            \"以下の文章を解析して、JSON形式で出力してください。\"\n",
        "            \"JSONには2つのキーを含めます：\"\n",
        "            \" 1) 'sentiment' : joy, surprise, confusion, neutral のいずれか\"\n",
        "            \" 2) 'ai_comment' : 短いポジティブコメント\"\n",
        "            \"出力は必ずJSON形式のみで返してください。\"\n",
        "        )\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-lite\",\n",
        "            config=genai.types.GenerateContentConfig(system_instruction=system_instruction),\n",
        "            contents=text\n",
        "        )\n",
        "        # JSON抽出\n",
        "        match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                result = json.loads(match.group())\n",
        "                sentiment = result.get(\"sentiment\",\"neutral\").strip().lower()\n",
        "                ai_comment = result.get(\"ai_comment\",\"\")\n",
        "            except:\n",
        "                sentiment = \"neutral\"\n",
        "                ai_comment = response.text\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "            ai_comment = response.text\n",
        "        if sentiment not in [\"joy\",\"surprise\",\"confusion\",\"neutral\"]:\n",
        "            sentiment = \"neutral\"\n",
        "        # DataFrame更新\n",
        "        df.loc[row_index,\"sentiment\"] = sentiment\n",
        "        df.loc[row_index,\"ai_comment\"] = ai_comment\n",
        "        latest_ai_comment = ai_comment\n",
        "        post_queue.task_done()\n",
        "        time.sleep(4)  # 15RPM制限に合わせて4秒に1回\n",
        "\n",
        "# バックグラウンドスレッド開始\n",
        "threading.Thread(target=process_queue, daemon=True).start()\n",
        "\n",
        "# --- 投稿処理 ---\n",
        "def submit_post(text):\n",
        "    global df, post_queue\n",
        "    row_index = len(df)\n",
        "    df.loc[row_index] = [text, \"pending\",\"\"]\n",
        "    post_queue.put((text,row_index))\n",
        "    fig, wc_image = update_visualizations()\n",
        "    return fig, wc_image, \"\", \"投稿完了。LLM解析は順番に処理されます。\"\n",
        "\n",
        "# --- 更新ボタン処理 ---\n",
        "def update_display():\n",
        "    fig, wc_image = update_visualizations()\n",
        "    return fig, wc_image, latest_ai_comment\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# オープンキャンパス感想SNSデモ\")\n",
        "    input_text = gr.Textbox(label=\"感想入力\")\n",
        "    submit_btn = gr.Button(\"投稿\")\n",
        "    update_btn = gr.Button(\"集計更新\")\n",
        "    ai_comment_output = gr.Textbox(label=\"AIコメント\", interactive=False)\n",
        "    status_output = gr.Textbox(label=\"投稿ステータス\", interactive=False)\n",
        "    graph_output = gr.Plot(label=\"感情分析グラフ\")\n",
        "    wc_output = gr.Image(label=\"ワードクラウド\")\n",
        "\n",
        "    # 投稿ボタン：集計グラフとワードクラウド更新 + 投稿ステータス表示\n",
        "    submit_btn.click(submit_post, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output, status_output])\n",
        "    # 更新ボタン：集計グラフ・ワードクラウド・最新AIコメント表示\n",
        "    update_btn.click(update_display, outputs=[graph_output, wc_output, ai_comment_output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "TUwgULX0jBi5",
        "outputId": "1dde21b4-f31b-45a9-e1e5-08df2621e1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-noto-cjk is already the newest version (1:20220127+repack1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://805bf316c755db9500.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://805bf316c755db9500.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai gradio plotly pandas wordcloud matplotlib\n",
        "!apt install -y fonts-noto-cjk\n",
        "import google.genai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image\n",
        "import json, re, threading, time, queue\n",
        "\n",
        "FONT_PATH = \"/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc\"\n",
        "\n",
        "# 投稿保存\n",
        "df = pd.DataFrame(columns=[\"投稿\",\"sentiment\",\"ai_comment\"])\n",
        "# LLM用キュー\n",
        "post_queue = queue.Queue()\n",
        "\n",
        "# --- 集計更新 ---\n",
        "def update_visualizations():\n",
        "    global df\n",
        "    # 棒グラフ\n",
        "    fig = px.histogram(\n",
        "        df,\n",
        "        x=\"sentiment\",\n",
        "        color=\"sentiment\",\n",
        "        text_auto=True,\n",
        "        category_orders={\"sentiment\":[\"joy\",\"surprise\",\"confusion\",\"neutral\"]},\n",
        "        title=\"オープンキャンパス感想のリアルタイム感情分析\",\n",
        "        color_discrete_map={\"joy\":\"gold\",\"surprise\":\"lightblue\",\"confusion\":\"orange\",\"neutral\":\"lightgrey\"}\n",
        "    )\n",
        "    fig.update_layout(yaxis_title=\"投稿数\", xaxis_title=\"感情\")\n",
        "    # ワードクラウド\n",
        "    all_text = \" \".join(df[\"投稿\"].tolist())\n",
        "    wc = WordCloud(width=400, height=300, background_color=\"white\", font_path=FONT_PATH).generate(all_text)\n",
        "    wc_image = wc.to_image()\n",
        "    return fig, wc_image\n",
        "\n",
        "# --- バックグラウンドLLM処理 ---\n",
        "def process_queue():\n",
        "    global df\n",
        "    while True:\n",
        "        try:\n",
        "            text, row_index = post_queue.get(timeout=1)\n",
        "        except queue.Empty:\n",
        "            time.sleep(1)\n",
        "            continue\n",
        "        # Gemini呼び出し\n",
        "        system_instruction = (\n",
        "            \"あなたはSNS分析の専門家です。\"\n",
        "            \"以下の文章を解析して、JSON形式で出力してください。\"\n",
        "            \"JSONには2つのキーを含めます：\"\n",
        "            \" 1) 'sentiment' : joy, surprise, confusion, neutral のいずれか\"\n",
        "            \" 2) 'ai_comment' : 短いポジティブコメント\"\n",
        "            \"出力は必ずJSON形式のみで返してください。\"\n",
        "        )\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash-lite\",\n",
        "            config=genai.types.GenerateContentConfig(system_instruction=system_instruction),\n",
        "            contents=text\n",
        "        )\n",
        "        # JSON抽出\n",
        "        match = re.search(r\"\\{.*\\}\", response.text, re.DOTALL)\n",
        "        if match:\n",
        "            try:\n",
        "                result = json.loads(match.group())\n",
        "                sentiment = result.get(\"sentiment\",\"neutral\").strip().lower()\n",
        "                ai_comment = result.get(\"ai_comment\",\"\")\n",
        "            except:\n",
        "                sentiment = \"neutral\"\n",
        "                ai_comment = response.text\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "            ai_comment = response.text\n",
        "        if sentiment not in [\"joy\",\"surprise\",\"confusion\",\"neutral\"]:\n",
        "            sentiment = \"neutral\"\n",
        "        # DataFrame更新\n",
        "        df.loc[row_index,\"sentiment\"] = sentiment\n",
        "        df.loc[row_index,\"ai_comment\"] = ai_comment\n",
        "        post_queue.task_done()\n",
        "        time.sleep(4)  # 15RPM制限に合わせて4秒に1回\n",
        "\n",
        "# バックグラウンドスレッド開始\n",
        "threading.Thread(target=process_queue, daemon=True).start()\n",
        "\n",
        "# --- 投稿処理 ---\n",
        "def submit_post(text):\n",
        "    global df, post_queue\n",
        "    row_index = len(df)\n",
        "    df.loc[row_index] = [text, \"pending\",\"pending\"]\n",
        "    post_queue.put((text,row_index))\n",
        "    fig, wc_image = update_visualizations()\n",
        "    return fig, wc_image, \"投稿完了。LLM解析は順番に処理されます。\"\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# オープンキャンパス感想SNSデモ\")\n",
        "    input_text = gr.Textbox(label=\"感想入力\")\n",
        "    submit_btn = gr.Button(\"投稿\")\n",
        "    update_btn = gr.Button(\"集計更新\")\n",
        "    ai_comment_output = gr.Textbox(label=\"AIコメント\", interactive=False)\n",
        "    graph_output = gr.Plot(label=\"感情分析グラフ\")\n",
        "    wc_output = gr.Image(label=\"ワードクラウド\")\n",
        "\n",
        "    submit_btn.click(submit_post, inputs=input_text, outputs=[graph_output, wc_output, ai_comment_output])\n",
        "    update_btn.click(lambda: update_visualizations(), outputs=[graph_output, wc_output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YcsvrLLHQuCS",
        "outputId": "b06a53eb-a583-4689-a25c-2244b2fec813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  fonts-noto-cjk-extra\n",
            "The following NEW packages will be installed:\n",
            "  fonts-noto-cjk\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 61.2 MB of archives.\n",
            "After this operation, 93.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-cjk all 1:20220127+repack1-1 [61.2 MB]\n",
            "Fetched 61.2 MB in 1s (61.4 MB/s)\n",
            "Selecting previously unselected package fonts-noto-cjk.\n",
            "(Reading database ... 126380 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-noto-cjk_1%3a20220127+repack1-1_all.deb ...\n",
            "Unpacking fonts-noto-cjk (1:20220127+repack1-1) ...\n",
            "Setting up fonts-noto-cjk (1:20220127+repack1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9fe3afa5c2a5e9a7c1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9fe3afa5c2a5e9a7c1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}